{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Classificação de Grãos de Trigo\n",
    "\n",
    "Este notebook contém a implementação do projeto de classificação de grãos de trigo usando aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação do Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Configurando o estilo dos gráficos\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Carregando o dataset\n",
    "df = pd.read_csv('seeds_dataset.txt', sep='\\t', header=None)\n",
    "\n",
    "# Renomeando as colunas\n",
    "df.columns = ['Area', 'Perimetro', 'Compacidade', 'Comprimento_Nucleo', 'Largura_Nucleo', 'Coeficiente_Assimetria', 'Comprimento_Sulco_Nucleo', 'Classe']\n",
    "\n",
    "print(\"Dataset carregado com sucesso. Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória de Dados (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo informações básicas do DataFrame\n",
    "print(\"Informações do DataFrame:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nEstatísticas descritivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Verificando valores ausentes\n",
    "print(\"\\nValores ausentes:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando visualizações\n",
    "\n",
    "# Histogramas para cada característica\n",
    "df.hist(figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para cada característica\n",
    "df.boxplot(figsize=(15, 6))\n",
    "plt.title(\"Boxplots das características\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de correlação\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot para identificar relações entre as características\n",
    "sns.pairplot(df, hue='Classe', height=2.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando features (X) e target (y)\n",
    "X = df.drop('Classe', axis=1)\n",
    "y = df['Classe']\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste (70% treinamento, 30% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Aplicando normalização (padronização) nas características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Shapes após divisão e normalização:\")\n",
    "print(\"X_train:\", X_train_scaled.shape)\n",
    "print(\"X_test:\", X_test_scaled.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementação e Comparação de Algoritmos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar o modelo\n",
    "def avaliar_modelo(y_true, y_pred, nome_modelo):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Resultados para {nome_modelo}:\")\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "    print(f\"Precisão: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusão - {nome_modelo}')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.xlabel('Valor Previsto')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "resultados = {}\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "resultados['KNN'] = avaliar_modelo(y_test, y_pred_knn, 'KNN')\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm.predict(X_test_scaled)\n",
    "resultados['SVM'] = avaliar_modelo(y_test, y_pred_svm, 'SVM')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "resultados['Random Forest'] = avaliar_modelo(y_test, y_pred_rf, 'Random Forest')\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "y_pred_nb = nb.predict(X_test_scaled)\n",
    "resultados['Naive Bayes'] = avaliar_modelo(y_test, y_pred_nb, 'Naive Bayes')\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "resultados['Logistic Regression'] = avaliar_modelo(y_test, y_pred_lr, 'Logistic Regression')\n",
    "\n",
    "# Comparação dos modelos\n",
    "df_resultados = pd.DataFrame(resultados, index=['Acurácia', 'Precisão', 'Recall', 'F1-score']).T\n",
    "print(\"\\nComparação dos modelos:\")\n",
    "print(df_resultados)\n",
    "\n",
    "# Visualização dos resultados\n",
    "df_resultados.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Comparação de Desempenho dos Modelos')\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Pontuação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Otimização dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para otimizar e avaliar o modelo\n",
    "def otimizar_modelo(modelo, param_grid, X_train, y_train, X_test, y_test, nome_modelo):\n",
    "    grid_search = GridSearchCV(modelo, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Melhores parâmetros para {nome_modelo}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    modelo_otimizado = grid_search.best_estimator_\n",
    "    y_pred = modelo_otimizado.predict(X_test)\n",
    "    \n",
    "    return avaliar_modelo(y_test, y_pred, f\"{nome_modelo} (Otimizado)\")\n",
    "\n",
    "# Otimização KNN\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance']}\n",
    "resultados['KNN (Otimizado)'] = otimizar_modelo(KNeighborsClassifier(), param_grid_knn, X_train_scaled, y_train, X_test_scaled, y_test, 'KNN')\n",
    "\n",
    "# Otimização SVM\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear'], 'gamma': ['scale', 'auto']}\n",
    "resultados['SVM (Otimizado)'] = otimizar_modelo(SVC(), param_grid_svm, X_train_scaled, y_train, X_test_scaled, y_test, 'SVM')\n",
    "\n",
    "# Otimização Random Forest\n",
    "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
    "resultados['Random Forest (Otimizado)'] = otimizar_modelo(RandomForestClassifier(random_state=42), param_grid_rf, X_train_scaled, y_train, X_test_scaled, y_test, 'Random Forest')\n",
    "\n",
    "# Otimização Logistic Regression\n",
    "param_grid_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'solver': ['lbfgs', 'liblinear']}\n",
    "resultados['Logistic Regression (Otimizado)'] = otimizar_modelo(LogisticRegression(random_state=42), param_grid_lr, X_train_scaled, y_train, X_test_scaled, y_test, 'Logistic Regression')\n",
    "\n",
    "# Comparação dos modelos otimizados\n",
    "df_resultados_otimizados = pd.DataFrame(resultados, index=['Acurácia', 'Precisão', 'Recall', 'F1-score']).T\n",
    "print(\"\\nComparação dos modelos otimizados:\")\n",
    "print(df_resultados_otimizados)\n",
    "\n",
    "# Visualização dos resultados otimizados\n",
    "df_resultados_otimizados.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Comparação de Desempenho dos Modelos Otimizados')\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Pontuação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpretação dos Resultados e Extração de Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando o melhor modelo\n",
    "melhor_modelo = df_resultados_otimizados['Acurácia'].idxmax()\n",
    "print(f\"\\nO melhor modelo é: {melhor_modelo}\")\n",
    "print(f\"Acurácia: {df_resultados_otimizados.loc[melhor_modelo, 'Acurácia']:.4f}\")\n",
    "\n",
    "# Análise da importância das características (para Random Forest)\n",
    "if 'Random Forest' in melhor_modelo:\n",
    "    importancias = rf.feature_importances_\n",
    "    caracteristicas = X.columns\n",
    "    indices = np.argsort(importancias)[::-1]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Importância das Características\")\n",
    "    plt.bar(range(X.shape[1]), importancias[indices])\n",
    "    plt.xticks(range(X.shape[1]), [caracteristicas[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nImportância das características:\")\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. %s (%f)\" % (f + 1, caracteristicas[indices[f]], importancias[indices[f]]))\n",
    "\n",
    "# Insights e conclusões\n",
    "print(\"\\nInsights e Conclusões:\")\n",
    "print(f\"1. O modelo {melhor_modelo} apresentou o melhor desempenho na classificação dos grãos de trigo.\")\n",
    "print(f\"2. A acurácia do melhor modelo ({df_resultados_otimizados.loc[melhor_modelo, 'Acurácia']:.4f}) sugere que é possível automatizar a classificação dos grãos de trigo com alta precisão.\")\n",
    "print(\"3. As características mais importantes para a classificação são...\")\n",
    "print(\"4. Recomenda-se a implementação deste modelo em um sistema de classificação automatizada para cooperativas agrícolas.\")\n",
    "print(\"5. Para melhorar ainda mais o desempenho, pode-se considerar a coleta de mais dados ou a engenharia de novas características.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusão e Próximos Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, desenvolvemos um modelo de classificação de grãos de trigo utilizando técnicas de aprendizado de máquina. Os principais pontos a serem destacados são:\n",
    "\n",
    "1. O melhor modelo obtido foi capaz de classificar corretamente os grãos de trigo com alta precisão.\n",
    "2. A análise das características mais importantes pode fornecer insights valiosos sobre os fatores que mais influenciam na classificação dos grãos.\n",
    "3. A automação deste processo de classificação pode trazer benefícios significativos para as cooperativas agrícolas, aumentando a eficiência e reduzindo erros humanos.\n",
    "\n",
    "Próximos passos:\n",
    "\n",
    "1. Implementar o modelo em um sistema de produção para uso prático nas cooperativas.\n",
    "2. Realizar testes em campo para validar o desempenho do modelo em condições reais.\n",
    "3. Considerar a expansão do modelo para classificar outros tipos de grãos além do trigo.\n",
    "4. Investigar a possibilidade de usar técnicas de deep learning, como redes neurais convolucionais, para melhorar ainda mais a precisão da classificação.\n",
    "5. Desenvolver uma interface amigável para que os usuários finais possam facilmente utilizar o modelo de classificação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
